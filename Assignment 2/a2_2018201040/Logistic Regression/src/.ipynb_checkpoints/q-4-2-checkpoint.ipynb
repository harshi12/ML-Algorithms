{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as mt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "eps = np.finfo(float).eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidianDistance(row1 , row2):\n",
    "    distance = 0\n",
    "    for i in range(1 , row2.shape[0] - 1):\n",
    "        distance += np.square(row1[i]-row2[i])\n",
    "    return np.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattanDistance(row1 , row2):\n",
    "    distance = 0\n",
    "    for i in range(1 , row2.shape[0] - 1):\n",
    "        distance += abs(row1[i]-row2[i])\n",
    "    return np.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minkowskiDistance(row1 , row2):\n",
    "    distance = 0\n",
    "    for i in range(1 , row2.shape[0] - 1):\n",
    "        distance += (abs(row1[i]-row2[i]))**3\n",
    "    return np.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distanceCalculator(df, row , distUsing = 'euclidian'):\n",
    "    distance = []\n",
    "    index = []\n",
    "    dist = 0\n",
    "    for i in range(0 ,len(df)):\n",
    "        if distUsing == 'euclidian':\n",
    "            dist = euclidianDistance(df.loc[i,:] , row)\n",
    "        if distUsing == 'manhattan':\n",
    "            dist = manhattanDistance(df.loc[i,:] , row)\n",
    "        if distUsing == 'minkowski':\n",
    "            dist = minkowskiDistance(df.loc[i,:] , row)\n",
    "        distance.append(dist)\n",
    "        index.append(i)\n",
    "    return [distance, index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortedDistanceDF(df , distance_index):\n",
    "    df['distance'] = distance_index[0]\n",
    "    df['index'] = distance_index[1]\n",
    "    df = df.sort_values(['distance','index'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def firstK(df,k):\n",
    "    return df.head(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority(df):\n",
    "    clValue,counts = np.unique(df[Class],return_counts=True)  \n",
    "    return clValue[np.argmax(counts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_algo(df, row, k, distUsing = 'euclidian'):\n",
    "    distance_index = distanceCalculator(df, row, distUsing)\n",
    "    df = sortedDistanceDF(df , distance_index)\n",
    "    df = firstK(df,k)\n",
    "    predict = majority(df);\n",
    "    return predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(confusion):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            if i==j:\n",
    "                correct += confusion[i][j]\n",
    "            total += confusion[i][j]\n",
    "    \n",
    "    return 100*correct/(float(total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(ClassValue, confusion):\n",
    "    true_positive = 0\n",
    "    true_negative = 0\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    for predict in range(0,2):\n",
    "        for actual in range(0,2):\n",
    "            if predict == ClassList.index(ClassValue) and actual == ClassList.index(ClassValue):\n",
    "                true_positive += confusion[predict][actual]\n",
    "            elif predict == ClassList.index(ClassValue) and actual != ClassList.index(ClassValue):\n",
    "                false_positive += confusion[predict][actual]\n",
    "            elif predict != ClassList.index(ClassValue) and actual == ClassList.index(ClassValue):\n",
    "                false_negative += confusion[predict][actual]\n",
    "            else:\n",
    "                true_negative += confusion[predict][actual]\n",
    "    return true_positive, true_negative, false_positive, false_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(true_positive , false_negative):\n",
    "    return true_positive*100/(true_positive +  false_negative+ eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(true_positive , false_positive):\n",
    "    return true_positive*100/(true_positive +  false_positive + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1score(recall , prescision):\n",
    "    return 2/(1/(float(recall)+eps)+1/(float(prescision)+eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotter(x_axis, y_axis):\n",
    "    plt.figure(num=None, figsize=(6, 4), dpi=150, facecolor='w', edgecolor='k')\n",
    "    # plotting the points  \n",
    "    plt.plot(x_axis, y_axis) \n",
    "    # naming the x axis \n",
    "    plt.xlabel('K') \n",
    "    # naming the y axis \n",
    "    plt.ylabel('Accuracy') \n",
    "\n",
    "    # giving a title to my graph \n",
    "    plt.title('Accuracy-vs-K') \n",
    "    plt.grid(True)\n",
    "    # function to show the plot \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(trainingSet, validationSet, distUsing = 'euclidian'):\n",
    "    listK = []\n",
    "    listACC = []\n",
    "    lastK = int(np.sqrt(len(trainingSet)))\n",
    "    print(\"Validating data set using \",distUsing,\" distance \")\n",
    "    for k in range(1 , lastK + 1):\n",
    "        confusion = [[0,0],[0,0]]\n",
    "        for index, row in validationSet.iterrows():\n",
    "            result = KNN_algo(trainingSet,row,k, distUsing)\n",
    "            confusion[ClassList.index(result)][ClassList.index(row[Class])] += 1\n",
    "        print(\"---------------------------------------------------------------------------------------------------\")\n",
    "        print(\"                                          FOR K = \", k)\n",
    "        print(\"---------------------------------------------------------------------------------------------------\")\n",
    "        print(\"confusion matrix: \")\n",
    "        for lst in confusion:\n",
    "            for i in lst:\n",
    "                print(i,\" \",end='')\n",
    "            print(\"\\n\")\n",
    "        print(\"----------------------------------------------------------------------\")\n",
    "        print(\" \")\n",
    "        acc = accuracy(confusion)\n",
    "        print (\"ACCURACY: \" , acc)\n",
    "        for ClassValue in ClassList:\n",
    "            true_positive, true_negative, false_positive, false_negative = scores(ClassValue , confusion)\n",
    "            rec = recall(true_positive , false_negative)\n",
    "            pre = precision(true_positive , false_positive)\n",
    "            f1 = f1score(rec, pre)\n",
    "            print(\" \")\n",
    "            print(\"------------Class Value \",ClassValue,\"Scores are------------\")\n",
    "            print(\" \")\n",
    "            print(\"RECALL: \", rec)\n",
    "            print(\"PRECISION: \", pre)\n",
    "            print(\"F1-score: \", f1)\n",
    "        print(\" \")\n",
    "        print(\"--END-END-END-END-END-END-END-END-END-END-END-END-END-END-END-END-END-END-END-END-END-END-END--\")\n",
    "        print(\" \")\n",
    "        listK.append(k)\n",
    "        listACC.append(acc)\n",
    "    plotter(listK, listACC)\n",
    "    return listK, listACC\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomDataSet = dataSet = pd.read_csv(\"./../input_data/AdmissionDataset/data.csv\")\n",
    "# randomDataSet = dataSet.sample(frac=1).reset_index(drop=True)\n",
    "Class = \"Chance of Admit\"\n",
    "columns = ['Serial No.' , 'GRE Score' , 'TOEFL Score' , 'University Rating' , 'SOP' , 'LOR' , 'CGPA' , 'Research' , Class]\n",
    "randomDataSet.columns = columns\n",
    "columns = columns[1:]\n",
    "randomDataSet = randomDataSet[columns]\n",
    "\n",
    "randomDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassBinaryList = []\n",
    "for i in range(0 , len(randomDataSet)):\n",
    "    if randomDataSet.iloc[i][-1] >= 0.5:\n",
    "        ClassBinaryList.append(1)\n",
    "    else:\n",
    "        ClassBinaryList.append(0)\n",
    "randomDataSet[Class] = ClassBinaryList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet, validationSet = np.split(randomDataSet, [int(0.8*len(randomDataSet))])\n",
    "clvalue,counts = np.unique(randomDataSet[Class],return_counts=True) \n",
    "ClassList = list(clvalue)\n",
    "# print(ClassList)\n",
    "# print(ClassList.index('Iris-virginica'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "validation(trainingSet, validationSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "validation(trainingSet, validationSet, 'manhattan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation(trainingSet, validationSet, 'minkowski')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
